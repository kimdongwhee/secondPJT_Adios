#ë¼ì´ë¸ŒëŸ¬ë¦¬
#from win32com.client import Dispatch #pywin
import streamlit as st
from streamlit_chat import message
import requests
import pandas as pd
import matplotlib
import seaborn
import numpy
from langchain_experimental.agents.agent_toolkits import create_pandas_dataframe_agent #ë­ì²´ì¸ : íŒë‹¤ìŠ¤ í˜¸í™˜ ë¼ì´ë¸ŒëŸ¬ë¦¬
from langchain_openai import ChatOpenAI #ë­ì²´ì¸ : ì±—ì˜¤í”ˆì• ì´ì•„ì´ ë¼ì´ë¸ŒëŸ¬ë¦¬
from langchain_core.messages import ChatMessage
from langchain_core.prompts import ChatPromptTemplate
import openai
#í™˜ê²½ë³€ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë° ì„¸íŒ…
import os
#API í™œìš©ë³„ í‚¤
myOpenAI_key = st.secrets["myOpenAI"]

#ë°ì´í„° ë¡œë“œ ë° ë³€ìˆ˜
all_player = pd.read_csv("./useData/total_all_position.csv", encoding="utf-16", index_col=0) #ì²«ì—´ ì‚­ì œë¥¼ ìœ„í•´ index_col ì‚¬ìš©
#=======================================================================================================================
#streamlit í˜ì´ì§€ í™œìš©ë²”ìœ„ ì„¤ì •
st.set_page_config(layout="wide")
#streamlití˜ì´ì§€ ì œëª©
st.header("The Football player data management with JavisğŸ¤–")
st.markdown("-----")
st.subheader(":one: Football Player Dataset")
st.dataframe(all_player, use_container_width=True, hide_index=True)
st.markdown("-----")
#=======================================================================================================================
#streamlit ì±—ë´‡ì˜ì—­
st.subheader(":two: Talking with JAVIS")

if "messages" not in st.session_state:
    st.session_state["messages"] = []

# ì´ì „ ëŒ€í™” ê¸°ë¡ì„ ì¶œë ¥í•˜ëŠ” ì½”ë“œ
if "messages" in st.session_state and len(st.session_state["messages"]) > 0:
    for chat_message in st.session_state["messages"]:
        st.chat_message(chat_message.role).write(chat_message.content)

if user_input := st.chat_input("ë¶„ì„í•  ë‚´ìš©ì„ ì…ë ¥í•´ì£¼ì„¸ìš”."):
    # ì‚¬ìš©ìê°€ ì…ë ¥í•œ ë‚´ìš©
    st.chat_message("user").write(f"{user_input}")
    # LLM ì‚¬ìš© í•˜ì—¬ AI ë‹µë³€ ìƒì„±
    #ë­ì²´ì¸
    # â”” ë­ì²´ì¸ MODEL
    llm = ChatOpenAI(model="gpt-3.5-turbo-0125", 
                 temperature = 0,
                 api_key = myOpenAI_key)

    #ëª¨ë¸ ì ìš©ì„ ë¶ˆëŸ¬ì˜¨ ë°ì´í„°ë³„ë¡œ ì„¤ì •
    # â”” gk ì œì™¸í•œ ëª¨ë“  í¬ì§€ì…˜ ë°ì´í„°
    agent_executor = create_pandas_dataframe_agent(
    llm,
    all_player,
    agent_type="openai-tools",
    verbose=True, #ë¶„ì„ë¡œê·¸
    return_intermediate_steps=True) #ì¤‘ê°„ê³¼ì •

    #ì§ˆë¬¸ ì „ë‹¬
    try:
        #responseì— ì…ë ¥ê°’ì´ ëª¨ë‘ ë‹´ê¹€.
        response = agent_executor.invoke(user_input)
        # response ì˜ ë”•ì…”ë„ˆë¦¬ì—ëŠ” response['intermediate_steps'] í‚¤ê°€ ìˆê±°ë‚˜ ì—†ì„ ë•Œê°€ ìˆìœ¼ë©°, ì´ëŠ” ì§ˆë¬¸ìœ í˜•ì— ë”°ë¼ ìƒì´í•¨
        # response ì˜ ë”•ì…”ë„ˆë¦¬ response['intermediate_steps'] ê°’ì´ 0ì¼ ë–„ëŠ” ì§ˆë¬¸ê³¼ ë‹µë§Œ ì¶œë ¥ í‘œì‹œ
        if len(response['intermediate_steps']) == 0: #reponse > intermediate_stepsê¸¸ì´ê°€ 0ì´ë©´ ì•„ë˜ ì½”ë“œ ì‹¤í–‰
            myAsk = response["input"] # response > inputì€ ì‚¬ìš©ìê°€ ì§ˆë¬¸í•œ ê°’
            AIresponse = response["output"] # response > outputì€ aiê°€ ë‹µë³€í•œ ê°’
            st.session_state["messages"].append(ChatMessage(role="user", content=myAsk)) #ëŒ€í™”ë‚´ìš© ì €ì¥
            # AI ë‹µë³€
            with st.chat_message("assistant"):
                st.write(AIresponse) #ai ë‹µë³€
                st.session_state["messages"].append(ChatMessage(role="assistant", content=AIresponse)) #ëŒ€í™”ë‚´ìš© ì €ì¥
        # response ì˜ ë”•ì…”ë„ˆë¦¬ response['intermediate_steps'] ê°’ì´ 1ì¼ ë–„ëŠ”  ë‘ê°€ì§€ ê²½ìš°ë¡œ ë‚˜ëˆ”. (1) .pltê°€ í¬í•¨ë˜ì–´ ìˆì„ ë•Œ  (2) pltê°€ í¬í•¨ì•ˆë˜ì–´ ìˆì„ë•Œ
        elif len(response['intermediate_steps']) == 1:
            myAsk = response["input"] # response > inputì€ ì‚¬ìš©ìê°€ ì§ˆë¬¸í•œ ê°’
            AIresponse = response["output"] # response > outputì€ aiê°€ ë‹µë³€í•œ ê°’
            st.session_state["messages"].append(ChatMessage(role="user", content=myAsk)) #ëŒ€í™”ë‚´ìš© ì €ì¥
            visual_query = response['intermediate_steps'][0][0].tool_input['query']  # reponse > intermediate_stepsê¸¸ì´ê°€ 0ì´ë©´ ì•„ë˜ ì½”ë“œ ì‹¤í–‰
            if "plt." not in visual_query: #(1) .pltê°€ í¬í•¨ë˜ì–´ ìˆì„ ë•Œ  : ì§ˆë¬¸ê³¼ ë‹µë§Œ ì¶œë ¥
                # AI ë‹µë³€
                with st.chat_message("assistant"):
                    st.write(AIresponse)
                    st.session_state["messages"].append(ChatMessage(role="assistant", content=AIresponse))
            else: #(2) pltê°€ í¬í•¨ì•ˆë˜ì–´ ìˆì„ë•Œ ì§ˆë¬¸ê³¼ ë‹µ ì´ë¯¸ì§€ ì¶œë ¥
                save_img = visual_query + "\nplt.savefig('./useData/save_fig_default.png')" #visual ì¿¼ë¦¬ëŠ” openaiê°€ ì‹œê°í™”ì°¨íŠ¸ë¥¼ ê·¸ë ¤ì¤€ íŒŒì´ì¬ ì½”ë“œê°€ ë‹´ê²¨ìˆìŒ. ê²½ë¡œë¥¼ ì§€ì •í•˜ì—¬ ì‹œê°í™” ì´ë¯¸ì§€ ìƒì„±í•˜ê³  ë‹µë³€ì—ì„œ í•¨ê¼ë³´ì—¬ì¤Œ
                df = all_player.copy() #ì‹œê°í™” íŒŒì´ì¬ ì½”ë“œë¥¼ ì¬ì‹¤í–‰í•˜ê¸°ìœ„í•´ í•´ë‹¹ì½”ë“œì™€ ì•„ë˜ì½”ë“œ ì‹¤í–‰
                finish_img = exec(save_img)
                # AI ë‹µë³€
                with st.chat_message("assistant"):
                    st.write(AIresponse) #ë‹µë³€
                    st.image("./useData/save_fig_default.png") #ìœ„ì—ì„œ ì €ì¥í•œ ì‹œê°í™”ì°¨íŠ¸ ì¶œë ¥
                    st.session_state["messages"].append(ChatMessage(role="assistant", content=AIresponse))

    #ì˜ˆì™¸ì²˜ë¦¬
    except openai.BadRequestError:
        st.session_state["messages"].append(ChatMessage(role="assistant", content="ì œê²Œ ì£¼ì‹  ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ í† í°ì´ ê¸°ì¤€ì¹˜ë³´ë‹¤ ì´ˆê³¼ ë˜ì—ˆìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ì§ˆë¬¸ ë¶€íƒí•´ìš”."))
