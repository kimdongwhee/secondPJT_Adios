#ë¼ì´ë¸ŒëŸ¬ë¦¬
import streamlit as st
from streamlit_chat import message
import requests
import pandas as pd
import matplotlib
import seaborn
import numpy
from langchain_experimental.agents.agent_toolkits import create_pandas_dataframe_agent #ë­ì²´ì¸ : íŒë‹¤ìŠ¤ í˜¸í™˜ ë¼ì´ë¸ŒëŸ¬ë¦¬
from langchain_openai import ChatOpenAI #ë­ì²´ì¸ : ì±—ì˜¤í”ˆì• ì´ì•„ì´ ë¼ì´ë¸ŒëŸ¬ë¦¬
from langchain_core.messages import ChatMessage
from langchain_core.prompts import ChatPromptTemplate
import openai
#í™˜ê²½ë³€ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë° ì„¸íŒ…
#from dotenv import load_dotenv
import os
#load_dotenv()
#API í™œìš©ë³„ í‚¤
myOpenAI_key = os.getenv("myOpenAI")

#ë°ì´í„° ë¡œë“œ ë° ë³€ìˆ˜
all_player = pd.read_csv("./useData/total_all_position.csv", encoding="utf-16", index_col=0) #ì²«ì—´ ì‚­ì œë¥¼ ìœ„í•´ index_col ì‚¬ìš©
#=======================================================================================================================
#streamlit í˜ì´ì§€ í™œìš©ë²”ìœ„ ì„¤ì •
st.set_page_config(layout="wide")
#streamlití˜ì´ì§€ ì œëª©
st.header("The Football player data management with JavisğŸ¤–")
st.markdown("-----")
st.subheader(":one: Football Player Dataset")
st.dataframe(all_player, use_container_width=True, hide_index=True)
st.markdown("-----")
#=======================================================================================================================
#streamlit ì±—ë´‡ì˜ì—­
st.subheader(":two: Talking with JAVIS")

if "messages" not in st.session_state:
    st.session_state["messages"] = []

# ì´ì „ ëŒ€í™” ê¸°ë¡ì„ ì¶œë ¥í•˜ëŠ” ì½”ë“œ
if "messages" in st.session_state and len(st.session_state["messages"]) > 0:
    for chat_message in st.session_state["messages"]:
        st.chat_message(chat_message.role).write(chat_message.content)

if user_input := st.chat_input("ë¶„ì„í•  ë‚´ìš©ì„ ì…ë ¥í•´ì£¼ì„¸ìš”."):
    # ì‚¬ìš©ìê°€ ì…ë ¥í•œ ë‚´ìš©
    st.chat_message("user").write(f"{user_input}")
    # LLM ì‚¬ìš© í•˜ì—¬ AI ë‹µë³€ ìƒì„±
    #ë­ì²´ì¸
    # â”” ë­ì²´ì¸ MODEL
    llm = ChatOpenAI(model="gpt-3.5-turbo-0125", 
                 temperature = 0,
                 api_key = myOpenAI_key)

    #ëª¨ë¸ ì ìš©ì„ ë¶ˆëŸ¬ì˜¨ ë°ì´í„°ë³„ë¡œ ì„¤ì •
    # â”” gk ì œì™¸í•œ ëª¨ë“  í¬ì§€ì…˜ ë°ì´í„°
    agent_executor = create_pandas_dataframe_agent(
    llm,
    all_player,
    agent_type="openai-tools",
    verbose=True, #ë¶„ì„ë¡œê·¸
    return_intermediate_steps=True) #ì¤‘ê°„ê³¼ì •

    #ì§ˆë¬¸ ì „ë‹¬
    try:
        response = agent_executor.invoke(user_input)
        if len(response['intermediate_steps']) == 0:
            myAsk = response["input"]
            AIresponse = response["output"]
            st.session_state["messages"].append(ChatMessage(role="user", content=myAsk))
            # AI ë‹µë³€
            with st.chat_message("assistant"):
                st.write(AIresponse)
                st.session_state["messages"].append(ChatMessage(role="assistant", content=AIresponse))
        else:
            myAsk = response["input"]
            AIresponse = response["output"]
            st.session_state["messages"].append(ChatMessage(role="user", content=myAsk))
    
            visual_query = response['intermediate_steps'][0][0].tool_input['query']
            if "plt." in visual_query:
                save_img = visual_query + "\nplt.savefig('./useData/save_fig_default.png')"
                df = all_player.copy()
                finish_img = exec(save_img)
            # AI ë‹µë³€
            with st.chat_message("assistant"):
                st.write(AIresponse)
                st.image("./useData/save_fig_default.png")
                st.session_state["messages"].append(ChatMessage(role="assistant", content=AIresponse))

    #ì˜ˆì™¸ì²˜ë¦¬
    except openai.BadRequestError:
        st.session_state["messages"].append(ChatMessage(role="assistant", content="ì œê²Œ ì£¼ì‹  ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ í† í°ì´ ê¸°ì¤€ì¹˜ë³´ë‹¤ ì´ˆê³¼ ë˜ì—ˆìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ì§ˆë¬¸ ë¶€íƒí•´ìš”."))
